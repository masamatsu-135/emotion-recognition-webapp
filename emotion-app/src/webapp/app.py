# app.py

from __future__ import annotations

from pathlib import Path
from typing import Literal
import sys

import streamlit as st
import numpy as np
import cv2
from PIL import Image

#from ..inference.predictor import EmotionPredictor
#from ..inference.face_detector import detect_and_crop_largest_face
#from ..inference.labels import EMOTION_LABELS_EN, EMOTION_LABELS_JA

PROJECT_ROOT = Path(__file__).resolve().parents[2]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.append(str(PROJECT_ROOT))

from src.inference.predictor import EmotionPredictor
from src.inference.face_detector import detect_and_crop_largest_face
from src.inference.labels import EMOTION_LABELS_EN, EMOTION_LABELS_JA

ModelType = Literal["cnn", "resnet"]

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆï¼ˆemotion-appï¼‰ã‚’ __file__ ã‹ã‚‰æ¨å®š
PROJECT_ROOT = Path(__file__).resolve().parents[2]
CHECKPOINT_DIR = PROJECT_ROOT / "models" / "checkpoints"


@st.cache_resource
def load_predictor(model_type: ModelType) -> EmotionPredictor:
    """
    ãƒ¢ãƒ‡ãƒ«ç¨®åˆ¥ã”ã¨ã« EmotionPredictor ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦ãŠãã€‚
    Streamlit ã®å†å®Ÿè¡Œã§ã‚‚æ¯å›ãƒ­ãƒ¼ãƒ‰ã—ç›´ã•ãªãã¦æ¸ˆã‚€ã€‚
    """
    if model_type == "cnn":
        ckpt = CHECKPOINT_DIR / "best_cnn_fer2013.pth"
    else:
        ckpt = CHECKPOINT_DIR / "best_resnet_fer2013.pth"

    predictor = EmotionPredictor(
        model_type=model_type,
        checkpoint_path=str(ckpt),
        device=None,  # GPUã‚ã‚Œã°GPUã€ãªã‘ã‚Œã°CPU
    )
    return predictor


def pil_to_bgr(image: Image.Image) -> np.ndarray:
    """
    PIL.Image (RGB) -> OpenCVå½¢å¼ BGR np.ndarray ã«å¤‰æ›
    """
    rgb = np.array(image)
    bgr = rgb[:, :, ::-1]
    return bgr


def draw_box_and_label(
    image_bgr: np.ndarray,
    box,
    label_ja: str,
    score: float,
) -> np.ndarray:
    """
    BGRç”»åƒã«ã€é¡”ã®æ ã¨ãƒ©ãƒ™ãƒ«ã‚’æç”»ã—ã¦è¿”ã™ã€‚
    """
    annotated = image_bgr.copy()
    x, y, w, h = box.as_tuple()

    # é¡”ã®æ 
    cv2.rectangle(annotated, (x, y), (x + w, y + h), (0, 255, 0), 2)

    # ãƒ©ãƒ™ãƒ«ãƒ†ã‚­ã‚¹ãƒˆ
    text = f"{label_ja} ({score:.2f})"
    cv2.putText(
        annotated,
        text,
        (x, y - 10),
        cv2.FONT_HERSHEY_SIMPLEX,
        0.6,
        (0, 255, 0),
        2,
        cv2.LINE_AA,
    )

    return annotated


def main():
    st.set_page_config(page_title="è¡¨æƒ…èªè­˜ãƒ‡ãƒ¢", page_icon="ğŸ™‚")
    st.title("è¡¨æƒ…èªè­˜ã‚¢ãƒ—ãƒªï¼ˆFER-2013ï¼‰")

    st.write("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”»åƒ or Webã‚«ãƒ¡ãƒ©ã‹ã‚‰é¡”ã®æ„Ÿæƒ…ã‚’æ¨å®šã—ã¾ã™ã€‚")

    # ==== ã‚µã‚¤ãƒ‰ãƒãƒ¼ ====
    st.sidebar.header("è¨­å®š")

    model_type: ModelType = st.sidebar.selectbox(
        "ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—",
        options=["cnn", "resnet"],
        format_func=lambda x: "CNNï¼ˆè»½é‡ï¼‰" if x == "cnn" else "ResNet-18ï¼ˆé«˜ç²¾åº¦ï¼‰",
    )

    st.sidebar.write("â€» ResNet ã¯å­¦ç¿’ã«GPUã‚’ä½¿ã„ã¾ã—ãŸãŒã€æ¨è«–ã¯CPUã§ã‚‚å‹•ä½œã—ã¾ã™ã€‚")

    # äºˆæ¸¬å®Ÿè¡Œãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸã¨ãã ã‘ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ãŸã„ã®ã§ã€å…ˆã«ãƒœã‚¿ãƒ³å®šç¾©
    input_mode = st.radio(
        "å…¥åŠ›æ–¹æ³•ã‚’é¸æŠã—ã¦ãã ã•ã„",
        options=["ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "Webã‚«ãƒ¡ãƒ©"],
        horizontal=True,
    )

    uploaded_image = None

    if input_mode == "ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰":
        file = st.file_uploader("é¡”ãŒå†™ã£ãŸç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["jpg", "jpeg", "png"])
        if file is not None:
            uploaded_image = Image.open(file).convert("RGB")
            st.image(uploaded_image, caption="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”»åƒ", use_column_width=True)
    else:
        camera_image = st.camera_input("Webã‚«ãƒ¡ãƒ©ã§æ’®å½±")
        if camera_image is not None:
            uploaded_image = Image.open(camera_image).convert("RGB")
            st.image(uploaded_image, caption="æ’®å½±ç”»åƒ", use_column_width=True)

    run_button = st.button("è¡¨æƒ…ã‚’æ¨å®šã™ã‚‹")

    if run_button:
        if uploaded_image is None:
            st.warning("å…ˆã«ç”»åƒã‚’ç”¨æ„ã—ã¦ãã ã•ã„ã€‚")
            return

        # ===== 1. ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ =====
        try:
            predictor = load_predictor(model_type)
        except FileNotFoundError as e:
            st.error(
                f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n{e}\n"
                "train.py ã§å­¦ç¿’ã‚’è¡Œã„ã€.pth ã‚’ models/checkpoints/ ã«é…ç½®ã—ã¦ãã ã•ã„ã€‚"
            )
            return

        # ===== 2. é¡”æ¤œå‡º =====
        bgr_image = pil_to_bgr(uploaded_image)
        box, face_img = detect_and_crop_largest_face(bgr_image, bgr=True)

        if face_img is None:
            st.error("é¡”ãŒæ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚åˆ¥ã®ç”»åƒã§è©¦ã—ã¦ã¿ã¦ãã ã•ã„ã€‚")
            return

        # ===== 3. æ„Ÿæƒ…æ¨å®š =====
        result = predictor.predict_from_ndarray(face_img, bgr=True)
        class_id = result["class_id"]
        label_ja = result["label_ja"]
        label_en = result["label_en"]
        probs = result["probs"]
        confidence = probs[class_id]

        st.subheader("æ¨å®šçµæœ")
        st.markdown(
            f"**äºˆæ¸¬ã•ã‚ŒãŸæ„Ÿæƒ…:** {label_ja}ï¼ˆ{label_en}ï¼‰  \n"
            f"**ç¢ºä¿¡åº¦:** {confidence:.2%}"
        )

        # ===== 4. å…¨ã‚¯ãƒ©ã‚¹ã®ç¢ºç‡ã‚’å¯è¦–åŒ– =====
        st.write("å„æ„Ÿæƒ…ã‚¯ãƒ©ã‚¹ã®ç¢ºç‡:")
        prob_dict = {
            f"{EMOTION_LABELS_JA[i]} ({EMOTION_LABELS_EN[i]})": probs[i]
            for i in range(len(probs))
        }
        st.bar_chart(prob_dict)

        # ===== 5. é¡”ã®æ ã‚’æç”»ã—ãŸç”»åƒã‚’è¡¨ç¤º =====
        annotated_bgr = draw_box_and_label(bgr_image, box, label_ja, confidence)
        annotated_rgb = annotated_bgr[:, :, ::-1]
        st.image(annotated_rgb, caption="æ¤œå‡ºã•ã‚ŒãŸé¡”ã¨æ¨å®šçµæœ", use_column_width=True)


if __name__ == "__main__":
    main()
